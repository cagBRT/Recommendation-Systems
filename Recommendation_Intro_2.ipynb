{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPiEIk4efaBTv5biRgi7FJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Recommendation-Systems/blob/main/Recommendation_Intro_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/recommendation-systems-explained-a42fc60591ed\n"
      ],
      "metadata": {
        "id": "7nFGJF-7lwpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "go to https://github.com/vatsal220/medium_articles/blob/main/rec_sys/data/data.csv\n",
        "\n",
        "download the dataset"
      ],
      "metadata": {
        "id": "tgdwx5GGi6XT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload it to the local directory"
      ],
      "metadata": {
        "id": "shbEOzaejEpA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXtMdrgliPmJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from random import randint\n",
        "\n",
        "def generate_data(n_books = 3000, n_genres = 10, n_authors = 450, n_publishers = 50, n_readers = 30000, dataset_size = 100000):\n",
        "    '''\n",
        "    This function will generate a dataset with features associated to\n",
        "    book data set. The dataset will have the following columns :\n",
        "        - book_id (String) : Unique identified for the book\n",
        "        - book_rating (Integer) : A value between 0 and 10\n",
        "        - reader_id (String) : Unique identifier for the user\n",
        "        - book_genre (Integer) : An integer representing a genre for the book,\n",
        "                                 value is between 1 and 15, indicating that\n",
        "                                 there are 15 unique genres. Each book can only\n",
        "                                 have 1 genre\n",
        "        - author_id (String) : Unique identifier for the author of the book\n",
        "        - num_pages (Integer) : Random value between 70 and 500\n",
        "        - publisher_id (String) : A unique identifier for the publisher of the book\n",
        "        - publish_year (Integer) : The year of book publishing\n",
        "        - book_price (Integer) : The sale price of the book\n",
        "        - text_lang (Integer) : The language of the book - returns an integer which\n",
        "                                is mapped to some language\n",
        "\n",
        "    params:\n",
        "        n_books (Integer) : The number of books you want the dataset to have\n",
        "        n_genres (Integer) : Number of genres to be chosen from\n",
        "        n_authors (Integer) : Number of authors to be generated\n",
        "        n_publishers (Integer) : Number of publishers for the dataset\n",
        "        n_readers (Integer) : Number of readers for the dataset\n",
        "        dataset_size (Integer) : The number of rows to be generated\n",
        "\n",
        "    example:\n",
        "        data = generate_data()\n",
        "    '''\n",
        "\n",
        "    d = pd.DataFrame(\n",
        "        {\n",
        "            'book_id' : [randint(1, n_books) for _ in range(dataset_size)],\n",
        "            'author_id' : [randint(1, n_authors) for _ in range(dataset_size)],\n",
        "            'book_genre' : [randint(1, n_genres) for _ in range(dataset_size)],\n",
        "            'reader_id' : [randint(1, n_readers) for _ in range(dataset_size)],\n",
        "            'num_pages' : [randint(75, 700) for _ in range(dataset_size)],\n",
        "            'book_rating' : [randint(1, 10) for _ in range(dataset_size)],\n",
        "            'publisher_id' : [randint(1, n_publishers) for _ in range(dataset_size)],\n",
        "            'publish_year' : [randint(2000, 2021) for _ in range(dataset_size)],\n",
        "            'book_price' : [randint(1, 200) for _ in range(dataset_size)],\n",
        "            'text_lang' : [randint(1,7) for _ in range(dataset_size)]\n",
        "        }\n",
        "    ).drop_duplicates()\n",
        "    return d\n",
        "\n",
        "d = generate_data(dataset_size = 100000)\n",
        "d.to_csv('data.csv', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation\n",
        "\n",
        "Import data from generate_data function (function provided above) or download the CSV from here\n",
        "Generate a pivot table with readers on the index and books on the column and values being the ratings\n",
        "Calculate similarity between items and users using svds\n",
        "Generate item recommendations based on user_id\n"
      ],
      "metadata": {
        "id": "0NQqn2XajKv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "def normalize(pred_ratings):\n",
        "    '''\n",
        "    This function will normalize the input pred_ratings\n",
        "\n",
        "    params:\n",
        "        pred_ratings (List -> List) : The prediction ratings\n",
        "    '''\n",
        "    return (pred_ratings - pred_ratings.min()) / (pred_ratings.max() - pred_ratings.min())\n",
        "\n",
        "def generate_prediction_df(mat, pt_df, n_factors):\n",
        "    '''\n",
        "    This function will calculate the single value decomposition of the input matrix\n",
        "    given n_factors. It will then generate and normalize the user rating predictions.\n",
        "\n",
        "    params:\n",
        "        mat (CSR Matrix) : scipy csr matrix corresponding to the pivot table (pt_df)\n",
        "        pt_df (DataFrame) : pandas dataframe which is a pivot table\n",
        "        n_factors (Integer) : Number of singular values and vectors to compute.\n",
        "                              Must be 1 <= n_factors < min(mat.shape).\n",
        "    '''\n",
        "\n",
        "    if not 1 <= n_factors < min(mat.shape):\n",
        "        raise ValueError(\"Must be 1 <= n_factors < min(mat.shape)\")\n",
        "\n",
        "    # matrix factorization\n",
        "    u, s, v = svds(mat, k = n_factors)\n",
        "    s = np.diag(s)\n",
        "\n",
        "    # calculate pred ratings\n",
        "    pred_ratings = np.dot(np.dot(u, s), v)\n",
        "    pred_ratings = normalize(pred_ratings)\n",
        "\n",
        "    # convert to df\n",
        "    pred_df = pd.DataFrame(\n",
        "        pred_ratings,\n",
        "        columns = pt_df.columns,\n",
        "        index = list(pt_df.index)\n",
        "    ).transpose()\n",
        "    return pred_df\n",
        "\n",
        "def recommend_items(pred_df, usr_id, n_recs):\n",
        "    '''\n",
        "    Given a usr_id and pred_df this function will recommend\n",
        "    items to the user.\n",
        "\n",
        "    params:\n",
        "        pred_df (DataFrame) : generated from `generate_prediction_df` function\n",
        "        usr_id (Integer) : The user you wish to get item recommendations for\n",
        "        n_recs (Integer) : The number of recommendations you want for this user\n",
        "    '''\n",
        "\n",
        "    usr_pred = pred_df[usr_id].sort_values(ascending = False).reset_index().rename(columns = {usr_id : 'sim'})\n",
        "    rec_df = usr_pred.sort_values(by = 'sim', ascending = False).head(n_recs)\n",
        "    return rec_df\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # constants\n",
        "    PATH = '../data/data.csv'\n",
        "\n",
        "    # import data\n",
        "    df = pd.read_csv('/content/data.csv')\n",
        "    print(df.shape)\n",
        "\n",
        "    # generate a pivot table with readers on the index and books on the column and values being the ratings\n",
        "    pt_df = df.pivot_table(\n",
        "        columns = 'book_id',\n",
        "        index = 'reader_id',\n",
        "        values = 'book_rating'\n",
        "    ).fillna(0)\n",
        "\n",
        "    # convert to a csr matrix\n",
        "    mat = pt_df.values\n",
        "    mat = csr_matrix(mat)\n",
        "\n",
        "    pred_df = generate_prediction_df(mat, pt_df, 10)\n",
        "\n",
        "    # generate recommendations\n",
        "    print(recommend_items(pred_df, 5, 5))"
      ],
      "metadata": {
        "id": "CSd8MvCrjP2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Content based filtering"
      ],
      "metadata": {
        "id": "CKzGTZkSkDMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation\n",
        "\n",
        "Import data from generate_data function (function provided above) or download the CSV from here\n",
        "Normalize book_price, book_ratings, num_pages\n",
        "One hot encode publish_year, book_genre, text_lang\n",
        "Given a book_id input, calculate the cosine similarity and return top n books similar to the input"
      ],
      "metadata": {
        "id": "hBY96lgakCbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import dataset: https://github.com/vatsal220/medium_articles/blob/main/rec_sys/data/data.csv\n",
        "\n"
      ],
      "metadata": {
        "id": "48tsuzlqj4nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def normalize(data):\n",
        "    '''\n",
        "    This function will normalize the input data to be between 0 and 1\n",
        "\n",
        "    params:\n",
        "        data (List) : The list of values you want to normalize\n",
        "\n",
        "    returns:\n",
        "        The input data normalized between 0 and 1\n",
        "    '''\n",
        "    min_val = min(data)\n",
        "    if min_val < 0:\n",
        "        data = [x + abs(min_val) for x in data]\n",
        "    max_val = max(data)\n",
        "    return [x/max_val for x in data]\n",
        "\n",
        "def ohe(df, enc_col):\n",
        "    '''\n",
        "    This function will one hot encode the specified column and add it back\n",
        "    onto the input dataframe\n",
        "\n",
        "    params:\n",
        "        df (DataFrame) : The dataframe you wish for the results to be appended to\n",
        "        enc_col (String) : The column you want to OHE\n",
        "\n",
        "    returns:\n",
        "        The OHE columns added onto the input dataframe\n",
        "    '''\n",
        "\n",
        "    ohe_df = pd.get_dummies(df[enc_col])\n",
        "    ohe_df.reset_index(drop = True, inplace = True)\n",
        "    return pd.concat([df, ohe_df], axis = 1)\n",
        "\n",
        "class CBRecommend():\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def cosine_sim(self, v1,v2):\n",
        "        '''\n",
        "        This function will calculate the cosine similarity between two vectors\n",
        "        '''\n",
        "        return sum(dot(v1,v2)/(norm(v1)*norm(v2)))\n",
        "\n",
        "    def recommend(self, book_id, n_rec):\n",
        "        \"\"\"\n",
        "        df (dataframe): The dataframe\n",
        "        song_id (string): Representing the song name\n",
        "        n_rec (int): amount of rec user wants\n",
        "        \"\"\"\n",
        "\n",
        "        # calculate similarity of input book_id vector w.r.t all other vectors\n",
        "        inputVec = self.df.loc[book_id].values\n",
        "        self.df['sim']= self.df.apply(lambda x: self.cosine_sim(inputVec, x.values), axis=1)\n",
        "\n",
        "        # returns top n user specified books\n",
        "        return self.df.nlargest(columns='sim',n=n_rec)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # constants\n",
        "    PATH = '../data/data.csv'\n",
        "\n",
        "    # import data\n",
        "    df = pd.read_csv('/content/data.csv')\n",
        "\n",
        "    # normalize the num_pages, ratings, price columns\n",
        "    df['num_pages_norm'] = normalize(df['num_pages'].values)\n",
        "    df['book_rating_norm'] = normalize(df['book_rating'].values)\n",
        "    df['book_price_norm'] = normalize(df['book_price'].values)\n",
        "\n",
        "    # OHE on publish_year and genre\n",
        "    df = ohe(df = df, enc_col = 'publish_year')\n",
        "    df = ohe(df = df, enc_col = 'book_genre')\n",
        "    df = ohe(df = df, enc_col = 'text_lang')\n",
        "\n",
        "    # drop redundant columns\n",
        "    cols = ['publish_year', 'book_genre', 'num_pages', 'book_rating', 'book_price', 'text_lang']\n",
        "    df.drop(columns = cols, inplace = True)\n",
        "    df.set_index('book_id', inplace = True)\n",
        "\n",
        "    # ran on a sample as an example\n",
        "    t = df.copy()\n",
        "    cbr = CBRecommend(df = t)\n",
        "    print(cbr.recommend(book_id = t.index[0], n_rec = 5))"
      ],
      "metadata": {
        "id": "jbxjSD0bkJB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation\n",
        "\n",
        "Import data from generate_data function (function provided above) or download the CSV from here\n",
        "Use a content-based model (cosine_similarity) to compute the 50 most similar books\n",
        "Compute the predicted ratings that the user might give these 50 books using a collaborative\n",
        "filtering model (SVD)\n",
        "Return the top n books with the highest predicted rating"
      ],
      "metadata": {
        "id": "_wp4BnvRk0_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise"
      ],
      "metadata": {
        "id": "rtCPhZaVlDCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import SVD, Reader, Dataset, accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "def hybrid(reader_id, book_id, n_recs, df, cosine_sim, svd_model):\n",
        "    '''\n",
        "    This function represents a hybrid recommendation system, it will have the following flow:\n",
        "        1. Use a content-based model (cosine_similarity) to compute the 50 most similar books\n",
        "        2. Compute the predicted ratings that the user might give these 50 books using a collaborative\n",
        "           filtering model (SVD)\n",
        "        3. Return the top n books with the highest predicted rating\n",
        "\n",
        "    params:\n",
        "        reader_id (Integer) : The reader_id\n",
        "        book_id (Integer) : The book_id\n",
        "        n_recs (Integer) : The number of recommendations you want\n",
        "        df (DataFrame) : Original dataframe with all book information\n",
        "        cosine_sim (DataFrame) : The cosine similarity dataframe\n",
        "        svd_model (Model) : SVD model\n",
        "    '''\n",
        "\n",
        "    # sort similarity values in decreasing order and take top 50 results\n",
        "    sim = list(enumerate(cosine_sim[int(book_id)]))\n",
        "    sim = sorted(sim, key=lambda x: x[1], reverse=True)\n",
        "    sim = sim[1:50]\n",
        "\n",
        "    # get book metadata\n",
        "    book_idx = [i[0] for i in sim]\n",
        "    books = df.iloc[book_idx][['book_id', 'book_rating', 'num_pages', 'publish_year', 'book_price', 'reader_id']]\n",
        "\n",
        "    # predict using the svd_model\n",
        "    books['est'] = books.apply(lambda x: svd_model.predict(reader_id, x['book_id'], x['book_rating']).est, axis = 1)\n",
        "\n",
        "    # sort predictions in decreasing order and return top n_recs\n",
        "    books = books.sort_values('est', ascending=False)\n",
        "    return books.head(n_recs)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # constants\n",
        "    PATH = '/content/data.csv'\n",
        "\n",
        "    # import data\n",
        "    df = pd.read_csv('/content/data.csv')\n",
        "\n",
        "    # content based\n",
        "    rmat = df.pivot_table(\n",
        "        columns = 'book_id',\n",
        "        index = 'reader_id',\n",
        "        values = 'book_rating'\n",
        "    ).fillna(0)\n",
        "\n",
        "    #Compute the cosine similarity matrix\n",
        "    cosine_sim = cosine_similarity(rmat, rmat)\n",
        "    cosine_sim = pd.DataFrame(cosine_sim, index=rmat.index, columns=rmat.index)\n",
        "\n",
        "    # collaborative filtering\n",
        "    reader = Reader()\n",
        "    data = Dataset.load_from_df(df[['reader_id', 'book_id', 'book_rating']], reader)\n",
        "\n",
        "    # split data into train test\n",
        "    trainset, testset = train_test_split(data, test_size=0.3,random_state=10)\n",
        "\n",
        "    # train\n",
        "    svd = SVD()\n",
        "    svd.fit(trainset)\n",
        "\n",
        "    # run the trained model against the testset\n",
        "    test_pred = svd.test(testset)\n",
        "\n",
        "    # get RMSE\n",
        "    accuracy.rmse(test_pred, verbose=True)\n",
        "\n",
        "    # generate recommendations\n",
        "    r_id = df['reader_id'].values[0]\n",
        "    b_id = df['book_id'].values[0]\n",
        "    n_recs = 5\n",
        "    print(hybrid(r_id, b_id, n_recs, df, cosine_sim, svd))"
      ],
      "metadata": {
        "id": "Tb7sI0MIkzpe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}